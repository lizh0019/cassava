{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015999,
     "end_time": "2021-03-09T13:00:20.851140",
     "exception": false,
     "start_time": "2021-03-09T13:00:20.835141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st Place Solution \"Cassava Leaf Disease Classification\"\n",
    "\n",
    "This is the inference notebook of our final submission which scored ~91.3% on public and private leaderboard. We used an ensemble of four different models and stacked those models together using a mean approach.\n",
    "\n",
    "You can find the according training code in these notebooks:\n",
    "\n",
    "* [EfficientNet B4 (TPU Training)](https://www.kaggle.com/jannish/cassava-leaf-disease-efficientnetb4-tpu)\n",
    "* [ResNext50_32x4d (GPU Training)](https://www.kaggle.com/hiarsl/cassava-leaf-disease-resnext50)\n",
    "* [ViT (TPU Training)](https://www.kaggle.com/sebastiangnther/cassava-leaf-disease-vit-tpu-training)\n",
    "\n",
    "In order to find the final combination of all the models we tested, we iteratively tried different ensembles using this notebook:\n",
    "\n",
    "* [Ensembling by using OOF predictions](https://www.kaggle.com/jannish/cassava-leaf-disease-finding-final-ensembles)\n",
    "\n",
    "Our final submission first averaged the probabilities of the predicted classes of ViT and ResNext. This averaged probability vector was then merged with the predicted probabilities of EfficientnetB4 and MobileNet(CropNet) in a second stage. For this purpose, the values were simply summed up.\n",
    "\n",
    "Finally, we would like to thank all the Kagglers who posted their notebooks and gave valuable hints on which models to try!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:00:20.889204Z",
     "iopub.status.busy": "2021-03-09T13:00:20.888445Z",
     "iopub.status.idle": "2021-03-09T13:00:32.796863Z",
     "shell.execute_reply": "2021-03-09T13:00:32.795458Z"
    },
    "papermill": {
     "duration": 11.931812,
     "end_time": "2021-03-09T13:00:32.797094",
     "exception": false,
     "start_time": "2021-03-09T13:00:20.865282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from functools import partial\n",
    "from albumentations import (Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, CenterCrop, \n",
    "                            HorizontalFlip, VerticalFlip, Rotate, ShiftScaleRotate, Transpose)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:00:32.838529Z",
     "iopub.status.busy": "2021-03-09T13:00:32.837644Z",
     "iopub.status.idle": "2021-03-09T13:00:32.858390Z",
     "shell.execute_reply": "2021-03-09T13:00:32.857713Z"
    },
    "papermill": {
     "duration": 0.047074,
     "end_time": "2021-03-09T13:00:32.858548",
     "exception": false,
     "start_time": "2021-03-09T13:00:32.811474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/cassava-leaf-disease-classification/\"\n",
    "image_path = path+\"test_images/\"\n",
    "\n",
    "IMAGE_SIZE = (512,512)\n",
    "submission_df = pd.DataFrame(columns={\"image_id\",\"label\"})\n",
    "submission_df[\"image_id\"] = os.listdir(image_path)\n",
    "submission_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014143,
     "end_time": "2021-03-09T13:00:32.887903",
     "exception": false,
     "start_time": "2021-03-09T13:00:32.873760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Used models in the final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:00:32.925181Z",
     "iopub.status.busy": "2021-03-09T13:00:32.923356Z",
     "iopub.status.idle": "2021-03-09T13:00:32.925957Z",
     "shell.execute_reply": "2021-03-09T13:00:32.926487Z"
    },
    "papermill": {
     "duration": 0.024541,
     "end_time": "2021-03-09T13:00:32.926675",
     "exception": false,
     "start_time": "2021-03-09T13:00:32.902134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We used this flag to test combinations using only TF.Keras models\n",
    "onlykeras = False\n",
    "        \n",
    "used_models_pytorch = {\"vit2020\": [f'../input/cassava-leaf-disease-1st-place-models/vit/vit_base_patch16_384_fold_{fold}.h5' for fold in [0,1,2,3,4]],\n",
    "                       \"resnext\": [f'../input/cassava-leaf-disease-1st-place-models/resnext50_32x4d/resnext50_32x4d_fold{fold}_best.pth' for fold in [0,1,2,3,4]]}\n",
    "\n",
    "used_models_keras = {\"mobilenet\": \"../input/cassava-leaf-disease-1st-place-models/cropnet_mobilenetv3/cropnet\",\n",
    "                     \"efficientnetb4\": \"../input/cassava-leaf-disease-1st-place-models/efficientnetb4/efficientnetb4_all_e14.h5\"}\n",
    "\n",
    "# We used this flag for testing different ensembling approaches\n",
    "stacked_mean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014107,
     "end_time": "2021-03-09T13:00:32.955119",
     "exception": false,
     "start_time": "2021-03-09T13:00:32.941012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ResNext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:00:33.398307Z",
     "iopub.status.busy": "2021-03-09T13:00:33.396643Z",
     "iopub.status.idle": "2021-03-09T13:00:52.671782Z",
     "shell.execute_reply": "2021-03-09T13:00:52.671127Z"
    },
    "papermill": {
     "duration": 19.702531,
     "end_time": "2021-03-09T13:00:52.671970",
     "exception": false,
     "start_time": "2021-03-09T13:00:32.969439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "        def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n",
    "            super().__init__()\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 5)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.model(x)\n",
    "            return x\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "\n",
    "if \"resnext\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                model.load_state_dict(state['model'])\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_resnext = pd.DataFrame(columns={\"image_id\"})\n",
    "    predictions_resnext[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_resnext['image_path_id'] = image_path + predictions_resnext['image_id'].astype(str)\n",
    "\n",
    "    model = CustomResNext('resnext50_32x4d', pretrained=False)\n",
    "    states = [torch.load(f) for f in used_models_pytorch[\"resnext\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_resnext, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_resnext['resnext'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_resnext = predictions_resnext.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014393,
     "end_time": "2021-03-09T13:00:52.701523",
     "exception": false,
     "start_time": "2021-03-09T13:00:52.687130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:00:52.759720Z",
     "iopub.status.busy": "2021-03-09T13:00:52.758791Z",
     "iopub.status.idle": "2021-03-09T13:01:28.141026Z",
     "shell.execute_reply": "2021-03-09T13:01:28.140390Z"
    },
    "papermill": {
     "duration": 35.425053,
     "end_time": "2021-03-09T13:01:28.141203",
     "exception": false,
     "start_time": "2021-03-09T13:00:52.716150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "if \"vit2020\" in used_models_pytorch:\n",
    "    \n",
    "    vit_image_size = 384\n",
    "    \n",
    "    class CustomViT(nn.Module):\n",
    "        def __init__(self, model_arch, n_class, pretrained=False):\n",
    "            super().__init__()\n",
    "            self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, n_class)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.model(x)\n",
    "            return x\n",
    "        \n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, df, transform=None):\n",
    "            self.df = df\n",
    "            self.file_names = df['image_path_id'].values\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            file_name = self.file_names[idx]\n",
    "            im_bgr = cv2.imread(file_name)\n",
    "            image = im_bgr[:, :, ::-1]\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "            return image\n",
    "\n",
    "    def get_tta_transforms():\n",
    "        return Compose([CenterCrop(vit_image_size, vit_image_size, p=1.),\n",
    "                Resize(vit_image_size, vit_image_size),\n",
    "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "                ToTensorV2(p=1.0)], p=1.)\n",
    "\n",
    "    def inference(models, test_loader, device):\n",
    "        tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "        probs = []\n",
    "        for i, (images) in tk0:\n",
    "            avg_preds = []\n",
    "            for model in models:\n",
    "                images = images.to(device)\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probs.append(avg_preds)\n",
    "        probs = np.concatenate(probs)\n",
    "        return probs\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    predictions_vit = pd.DataFrame(columns={\"image_id\"})\n",
    "    predictions_vit[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_vit['image_path_id'] = image_path + predictions_vit['image_id'].astype(str)\n",
    "\n",
    "    def load_cassava_vit(modelpath):\n",
    "        _model = CustomViT('vit_base_patch16_384', 5, pretrained=False)\n",
    "        _model.load_state_dict(torch.load(modelpath))\n",
    "        _model.eval()\n",
    "        return _model\n",
    "\n",
    "    models = [load_cassava_vit(f) for f in used_models_pytorch[\"vit2020\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_vit, transform=get_tta_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    predictions_raw_vit = inference(models, test_loader, device)\n",
    "\n",
    "    predictions_vit['vit2020'] = [np.squeeze(p) for p in predictions_raw_vit]\n",
    "    predictions_vit = predictions_vit.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        for model in models:\n",
    "            del(model)\n",
    "    except:\n",
    "        pass\n",
    "    models = []\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015811,
     "end_time": "2021-03-09T13:01:28.174538",
     "exception": false,
     "start_time": "2021-03-09T13:01:28.158727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Mobilenet V3 (CropNet)\n",
    "\n",
    "There are multiple ways to include pretrained models from [TensorFlow Hub](https://www.tensorflow.org/hub/tutorials/cropnet_cassava), if internet has to be turned of during submission:\n",
    "\n",
    "* Accessing and storing the .tar.gz file (see [this](https://xianbao-qian.medium.com/how-to-run-tf-hub-locally-without-internet-connection-4506b850a915) Medium post) \n",
    "<code>\n",
    "!curl -LO https://storage.googleapis.com/tfhub-modules/google/cropnet/classifier/cassava_disease_V1/2.tar.gz\n",
    "!mkdir cropnet_mobilenetv3\n",
    "!tar -xf 2.tar.gz  --directory cropnet_mobilenetv3    \n",
    "</code>\n",
    "<br>\n",
    "\n",
    "* Downloading and caching the weights using\n",
    "<code>\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"/kaggle/working\"\n",
    "hub.KerasLayer('https://tfhub.dev/google/cropnet/classifier/cassava_disease_V1/2', trainable=False)\n",
    "</code>\n",
    "<br>\n",
    "\n",
    "You can find more [information on caching on the official tfhub website](https://www.tensorflow.org/hub/caching) and more information on the [pretrained CropNet model ](https://tfhub.dev/google/cropnet/classifier/cassava_disease_V1/2). For the offline submissions we included these weights into a Kaggle Dataset bucket.\n",
    "\n",
    "Remark: In the meantime, TFHub models can apparently be integrated directly into the TPU training via Kaggle. Check out the[ Kaggle TPU FAQs](https://www.kaggle.com/product-feedback/216256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:28.213404Z",
     "iopub.status.busy": "2021-03-09T13:01:28.212621Z",
     "iopub.status.idle": "2021-03-09T13:01:28.425898Z",
     "shell.execute_reply": "2021-03-09T13:01:28.424571Z"
    },
    "papermill": {
     "duration": 0.235608,
     "end_time": "2021-03-09T13:01:28.426085",
     "exception": false,
     "start_time": "2021-03-09T13:01:28.190477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "def build_mobilenet3(img_size=(224,224), weights=\"../input/cassava-leaf-disease-1st-place-models/cropnet_mobilenetv3/cropnet\"):\n",
    "    classifier = hub.KerasLayer(weights)\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "    hub.KerasLayer(classifier, trainable=False)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016105,
     "end_time": "2021-03-09T13:01:28.459062",
     "exception": false,
     "start_time": "2021-03-09T13:01:28.442957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keras Inference with TTA\n",
    "\n",
    "For the included EfficientNets we used simple test time augmentations (Flip, Rotate, Transpose). To do this, we cropped 4 overlapping patches of size 512x512 from the .jpg images and applied 2 augmentations to each patch. We retain two additional center-cropped patches of the image to which no augmentations were applied. To get an overall prediction, we took the average of all these image tiles.\n",
    "\n",
    "For the CropNet, we just center-cropped and resized the image. In addition, we distributed the unknown class evenly over the 5 leaf diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:28.521437Z",
     "iopub.status.busy": "2021-03-09T13:01:28.520580Z",
     "iopub.status.idle": "2021-03-09T13:01:49.384470Z",
     "shell.execute_reply": "2021-03-09T13:01:49.385626Z"
    },
    "papermill": {
     "duration": 20.910535,
     "end_time": "2021-03-09T13:01:49.385858",
     "exception": false,
     "start_time": "2021-03-09T13:01:28.475323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.26s/it]\n"
     ]
    }
   ],
   "source": [
    "def image_augmentations(image):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    if p_spatial > 0.75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    if p_rotate > 0.75:\n",
    "        image = tf.image.rot90(image, k = 3)\n",
    "    elif p_rotate > 0.5:\n",
    "        image = tf.image.rot90(image, k = 2)\n",
    "    elif p_rotate > 0.25:\n",
    "        image = tf.image.rot90(image, k = 1)\n",
    "\n",
    "    image = tf.image.resize(image, size = IMAGE_SIZE)\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    \n",
    "    return image\n",
    "\n",
    "def read_preprocess_file(img_path, normalize=False):\n",
    "    image = Image.open(img_path)\n",
    "    if normalize:\n",
    "        img_scaled = np.array(image)/ 255.0\n",
    "    else:\n",
    "        img_scaled = np.array(image)\n",
    "    img_scaled = img_scaled.astype(np.float32)\n",
    "    return (image.size[0], image.size[1]), img_scaled\n",
    "\n",
    "def create_image_tiles(origin_dim, processed_img):\n",
    "    crop_size = 512\n",
    "    img_list = []\n",
    "    # Cut image into 4 overlapping patches\n",
    "    for x in [0, origin_dim[1] - crop_size]:\n",
    "        for y in [0, origin_dim[0] - crop_size]:\n",
    "            img_list.append(processed_img[x:x+crop_size , y:y+crop_size,:])\n",
    "    # Keep one additional center cropped image \n",
    "    img_list.append(cv2.resize(processed_img[:, 100:700 ,:], dsize=(crop_size, crop_size)))\n",
    "    return np.array(img_list)\n",
    "\n",
    "def augment_tiles_light(tiles, ttas=2):\n",
    "  # Copy central croped image to have same ratio to augmented images\n",
    "  holdout = np.broadcast_to(tiles[-1,:,:,:],(ttas,) + tiles.shape[1:])\n",
    "  augmented_batch = tf.map_fn(lambda x: image_augmentations(x), tf.concat(\n",
    "      [tiles[:-1,:,:,:] for _ in range(ttas)], axis=0))\n",
    "  return tf.concat([augmented_batch, holdout], axis=0)\n",
    "\n",
    "def cut_crop_image(processed_img):\n",
    "    image = tf.image.central_crop(processed_img, 0.8)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    return np.expand_dims(image, 0)\n",
    "\n",
    "# CropNet class 6 (unknown) is distributed evenly over all 5 classes to match problem setting\n",
    "def distribute_unknown(propabilities):\n",
    "    return propabilities[:,:-1] + np.expand_dims(propabilities[:,-1]/5, 1)\n",
    "\n",
    "def multi_predict_tfhublayer(img_path, modelinstance):\n",
    "    img = cut_crop_image(read_preprocess_file(img_path, True)[1])\n",
    "    yhat = modelinstance.predict(img)\n",
    "    return np.mean(distribute_unknown(yhat), axis=0)\n",
    "\n",
    "def multi_predict_keras(img_path, modelinstance, *args):\n",
    "    augmented_batch = augment_tiles_light(create_image_tiles(\n",
    "        *read_preprocess_file(img_path)))\n",
    "    Yhat = modelinstance.predict(augmented_batch)\n",
    "    return np.mean(Yhat, axis=0)\n",
    "\n",
    "def predict_and_vote(image_list, modelinstances, onlykeras):\n",
    "    predictions = [] \n",
    "    with tqdm(total=len(image_list)) as process_bar:       \n",
    "      for img_path in image_list:\n",
    "        process_bar.update(1)  \n",
    "        Yhats = np.vstack([func(img_path, modelinstance) for func, modelinstance in modelinstances])\n",
    "        if onlykeras:\n",
    "            predictions.append(np.argmax(np.sum(Yhats, axis=0)))\n",
    "        else:\n",
    "            predictions.append(Yhats)    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "inference_models = []\n",
    "\n",
    "if \"mobilenet\" in used_models_keras:\n",
    "    model_mobilenet = build_mobilenet3(weights=used_models_keras[\"mobilenet\"])\n",
    "    inference_models.append((multi_predict_tfhublayer, model_mobilenet))\n",
    "    \n",
    "if \"efficientnetb4\" in used_models_keras:\n",
    "    model_efficientnetb4 =  keras.models.load_model(used_models_keras[\"efficientnetb4\"], compile=False)\n",
    "    inference_models.append((multi_predict_keras, model_efficientnetb4))\n",
    "    \n",
    "if \"efficientnetb5\" in used_models_keras:\n",
    "    model_efficientnetb5 =  keras.models.load_model(used_models_keras[\"efficientnetb5\"])\n",
    "    inference_models.append((multi_predict_keras, model_efficientnetb5))\n",
    "\n",
    "submission_df[\"label\"] = predict_and_vote([image_path+id for id in submission_df[\"image_id\"].values], inference_models, onlykeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:49.447853Z",
     "iopub.status.busy": "2021-03-09T13:01:49.446963Z",
     "iopub.status.idle": "2021-03-09T13:01:49.737225Z",
     "shell.execute_reply": "2021-03-09T13:01:49.736152Z"
    },
    "papermill": {
     "duration": 0.327407,
     "end_time": "2021-03-09T13:01:49.737387",
     "exception": false,
     "start_time": "2021-03-09T13:01:49.409980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "try:\n",
    "    del inference_models[:]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018179,
     "end_time": "2021-03-09T13:01:49.774391",
     "exception": false,
     "start_time": "2021-03-09T13:01:49.756212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Ensembling\n",
    "\n",
    "Our winning submission just included CropNet, EfficientNet B4, ResNext50 and ViT and a mean approach. We took the mean of the class weights from the ResNext and ViT model and combined this combination with the MobileNet and the EfficientnetB4 in the second stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:49.830893Z",
     "iopub.status.busy": "2021-03-09T13:01:49.829747Z",
     "iopub.status.idle": "2021-03-09T13:01:49.840623Z",
     "shell.execute_reply": "2021-03-09T13:01:49.839528Z"
    },
    "papermill": {
     "duration": 0.047984,
     "end_time": "2021-03-09T13:01:49.840773",
     "exception": false,
     "start_time": "2021-03-09T13:01:49.792789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(list(used_models_keras.keys())) <= 1:\n",
    "    submission_df.loc[:,list(used_models_keras)[0]] = submission_df[\"label\"].explode()\n",
    "else:\n",
    "    tmp = (submission_df['label'].transform([lambda x:x[0], lambda x:x[1]]).set_axis(list(used_models_keras.keys()), axis=1, inplace=False))\n",
    "    submission_df = submission_df.merge(tmp, right_index=True, left_index=True)\n",
    "    \n",
    "submission_df[\"label\"] = 0\n",
    "\n",
    "if \"resnext\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_resnext, on=\"image_id\")\n",
    "    \n",
    "if \"efficientnetb3\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_cutmix, on=\"image_id\")\n",
    "    \n",
    "if \"vit2020\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_vit, on=\"image_id\")\n",
    "    \n",
    "if \"vit2019\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_vit2019, on=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:49.886218Z",
     "iopub.status.busy": "2021-03-09T13:01:49.885367Z",
     "iopub.status.idle": "2021-03-09T13:01:49.894738Z",
     "shell.execute_reply": "2021-03-09T13:01:49.893631Z"
    },
    "papermill": {
     "duration": 0.035761,
     "end_time": "2021-03-09T13:01:49.894884",
     "exception": false,
     "start_time": "2021-03-09T13:01:49.859123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if stacked_mean:\n",
    "    submission_df[\"stage_1\"] = submission_df.apply(lambda row: [np.mean(e) for e in zip(row[\"vit2020\"], row[\"resnext\"])], axis=1)\n",
    "    submission_df[\"label\"] = submission_df.apply(lambda row: np.argmax(\n",
    "        [np.sum(e) for e in zip(row[\"mobilenet\"],row[\"stage_1\"], row[\"efficientnetb4\"])]), axis=1)        \n",
    "else:\n",
    "    submission_df[\"label\"] = submission_df.apply(lambda row: np.argmax(\n",
    "        [np.sum(e) for e in zip(*[row[m] for m in list(used_models_pytorch.keys())+list(used_models_keras.keys())])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:49.945256Z",
     "iopub.status.busy": "2021-03-09T13:01:49.944395Z",
     "iopub.status.idle": "2021-03-09T13:01:49.956870Z",
     "shell.execute_reply": "2021-03-09T13:01:49.957433Z"
    },
    "papermill": {
     "duration": 0.044427,
     "end_time": "2021-03-09T13:01:49.957643",
     "exception": false,
     "start_time": "2021-03-09T13:01:49.913216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image_id</th>\n",
       "      <th>mobilenet</th>\n",
       "      <th>efficientnetb4</th>\n",
       "      <th>resnext</th>\n",
       "      <th>vit2020</th>\n",
       "      <th>stage_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>[0.0039915927, 0.0037076094, 0.8709406, 0.0065...</td>\n",
       "      <td>[0.10107932, 0.12100544, 0.30475152, 0.0873998...</td>\n",
       "      <td>[0.030495385, 0.008266998, 0.5979506, 0.034923...</td>\n",
       "      <td>[0.0029346456, 0.011939395, 0.6290571, 0.01440...</td>\n",
       "      <td>[0.016715014, 0.010103197, 0.6135038, 0.024666...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        image_id                                          mobilenet  \\\n",
       "0      2  2216849948.jpg  [0.0039915927, 0.0037076094, 0.8709406, 0.0065...   \n",
       "\n",
       "                                      efficientnetb4  \\\n",
       "0  [0.10107932, 0.12100544, 0.30475152, 0.0873998...   \n",
       "\n",
       "                                             resnext  \\\n",
       "0  [0.030495385, 0.008266998, 0.5979506, 0.034923...   \n",
       "\n",
       "                                             vit2020  \\\n",
       "0  [0.0029346456, 0.011939395, 0.6290571, 0.01440...   \n",
       "\n",
       "                                             stage_1  \n",
       "0  [0.016715014, 0.010103197, 0.6135038, 0.024666...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T13:01:50.004303Z",
     "iopub.status.busy": "2021-03-09T13:01:50.003392Z",
     "iopub.status.idle": "2021-03-09T13:01:51.000956Z",
     "shell.execute_reply": "2021-03-09T13:01:51.002355Z"
    },
    "papermill": {
     "duration": 1.025595,
     "end_time": "2021-03-09T13:01:51.002617",
     "exception": false,
     "start_time": "2021-03-09T13:01:49.977022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id,label\r\n",
      "2216849948.jpg,2\r\n"
     ]
    }
   ],
   "source": [
    "submission_df[[\"image_id\",\"label\"]].to_csv(\"submission.csv\", index=False)\n",
    "!head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 100.911208,
   "end_time": "2021-03-09T13:01:55.304211",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-09T13:00:14.393003",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
